name: Deploy Portainer Stacks

on:
  push:
    branches: [main]
    paths:
      - 'portainer/terraform/*.tf'
      - 'portainer/stacks/**/*.yml'
      - 'portainer/stacks/**/*.env'
  workflow_dispatch:
    inputs:
      service:
        description: 'Specific service to deploy (optional)'
        required: false
        type: string
  workflow_run:
    workflows: ["Push SOPS Secrets to GitHub"]
    types:
      - completed
    branches:
      - main

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      services: ${{ steps.detect.outputs.services }}
      all-services: ${{ steps.detect.outputs.all-services }}
      all-services-list: ${{ steps.detect.outputs.all-services-list }}
      has_infra_changes: ${{ steps.detect.outputs.has_infra_changes }}
      deleted-services: ${{ steps.detect.outputs.deleted-services }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 2

    - name: Debug event info
      run: |
        echo "Event name: ${{ github.event_name }}"
        echo "Manual service input: ${{ github.event.inputs.service }}"
        echo "Workflow run conclusion: ${{ github.event.workflow_run.conclusion }}"

    - name: Detect changed services
      id: detect
      run: |
        # If manual dispatch with specific service
        if [ "${{ github.event.inputs.service }}" != "" ]; then
          echo "services=[\"${{ github.event.inputs.service }}\"]" >> $GITHUB_OUTPUT
          echo "all-services=false" >> $GITHUB_OUTPUT
          echo "has_infra_changes=false" >> $GITHUB_OUTPUT
          echo "deleted-services=[]" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Get changed files - handle case where there's no previous commit
        if git rev-parse --verify HEAD^ >/dev/null 2>&1; then
          CHANGED_FILES=$(git diff --name-only HEAD^ HEAD)
          # Detect deleted .tf files (services that were removed)
          DELETED_TF_FILES=$(git diff --name-only --diff-filter=D HEAD^ HEAD | grep -E '^portainer/terraform/[^/]+\.tf$' | grep -vE '(main|backend|vars|provider|network)\.tf$' || true)
        else
          # First commit - check all files
          CHANGED_FILES=$(git ls-files)
          DELETED_TF_FILES=""
        fi
        
        echo "Changed files: $CHANGED_FILES"
        echo "Deleted TF files: $DELETED_TF_FILES"
        
        # Extract deleted service names
        if [ -n "$DELETED_TF_FILES" ]; then
          DELETED_SERVICES=$(echo "$DELETED_TF_FILES" | xargs -n1 basename | sed 's/\.tf$//' | jq -R -s -c 'split("\n") | map(select(length > 0))')
        else
          DELETED_SERVICES='[]'
        fi
        echo "Deleted services: $DELETED_SERVICES"
        echo "deleted-services=$DELETED_SERVICES" >> $GITHUB_OUTPUT
        
        # Check for infrastructure changes
        if echo "$CHANGED_FILES" | grep -q "portainer/terraform/\(main\|backend\|vars\|provider\|network\)\.tf"; then
          echo "has_infra_changes=true" >> $GITHUB_OUTPUT
          # Get all service names from terraform files
          SERVICES=$(find portainer/terraform -maxdepth 1 -name "*.tf" -not -name "main.tf" -not -name "backend.tf" -not -name "vars.tf" -not -name "provider.tf" -not -name "network.tf" | xargs -n1 basename | sed 's/\.tf$//' | jq -R -s -c 'split("\n")[:-1]')
          echo "services=$SERVICES" >> $GITHUB_OUTPUT
          echo "all-services=true" >> $GITHUB_OUTPUT
          exit 0
        else
          echo "has_infra_changes=false" >> $GITHUB_OUTPUT
        fi
        
        # Extract unique service names from changed files
        SERVICES=$(echo "$CHANGED_FILES" | grep -E '\.(tf|yml|env)$' | while read file; do
          if [[ "$file" =~ portainer/terraform/([^/]+)\.tf$ ]] && [[ "${BASH_REMATCH[1]}" != "main" ]] && [[ "${BASH_REMATCH[1]}" != "backend" ]] && [[ "${BASH_REMATCH[1]}" != "vars" ]] && [[ "${BASH_REMATCH[1]}" != "provider" ]] && [[ "${BASH_REMATCH[1]}" != "network" ]]; then
            echo "${BASH_REMATCH[1]}"
          elif [[ "$file" =~ portainer/stacks/([^/]+)/ ]]; then
            echo "${BASH_REMATCH[1]}"
          fi
        done | sort -u | jq -R -s -c 'split("\n")[:-1]')
        
        # If no services were detected from changes, check for new services
        if [ "$SERVICES" = "[]" ]; then
          # Get all service names from terraform files
          SERVICES=$(find portainer/terraform -maxdepth 1 -name "*.tf" -not -name "main.tf" -not -name "backend.tf" -not -name "vars.tf" -not -name "provider.tf" -not -name "network.tf" | xargs -n1 basename | sed 's/\.tf$//' | jq -R -s -c 'split("\n")[:-1]')
        fi
        
        echo "Detected services: $SERVICES"
        echo "services=$SERVICES" >> $GITHUB_OUTPUT
        echo "all-services=false" >> $GITHUB_OUTPUT
        # Get ALL services for when infrastructure changes
        ALL_SERVICES_LIST=$(find portainer/terraform -maxdepth 1 -name "*.tf" -not -name "main.tf" -not -name "backend.tf" -not -name "vars.tf" -not -name "provider.tf" -not -name "network.tf" | xargs -n1 basename | sed 's/\.tf$//' | jq -R -s -c 'split("\n")[:-1]')
        echo "all-services-list=$ALL_SERVICES_LIST" >> $GITHUB_OUTPUT

    - name: Debug outputs
      run: |
        echo "Services output: ${{ steps.detect.outputs.services }}"
        echo "All services output: ${{ steps.detect.outputs.all-services }}"
        echo "Has infra changes: ${{ steps.detect.outputs.has_infra_changes }}"
        echo "Services JSON: ${{ steps.detect.outputs.services }}"
        echo "Services not empty: ${{ steps.detect.outputs.services != '[]' }}"

    - name: Ensure valid JSON outputs
      run: |
        # Fix services output
        SERVICES=$(echo '${{ steps.detect.outputs.services }}' | tr -d '\n\r' | grep -v '^$' || echo '[]')
        if [ -z "$SERVICES" ] || [ "$SERVICES" = "null" ] || [ "$SERVICES" = '""' ]; then
          SERVICES='[]'
        fi
        echo "services=$SERVICES" >> $GITHUB_OUTPUT
        
        # Fix all-services-list output  
        ALL_SERVICES=$(echo '${{ steps.detect.outputs.all-services-list }}' | tr -d '\n\r' | grep -v '^$' || echo '[]')
        if [ -z "$ALL_SERVICES" ] || [ "$ALL_SERVICES" = "null" ] || [ "$ALL_SERVICES" = '""' ]; then
          ALL_SERVICES='[]'
        fi
        echo "all-services-list=$ALL_SERVICES" >> $GITHUB_OUTPUT
          
  deploy-infrastructure:
    needs: detect-changes
    runs-on: ubuntu-latest
    if: ${{ needs.detect-changes.outputs.has_infra_changes == 'true' && (github.event_name == 'workflow_dispatch' || github.event_name == 'push' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')) }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: "1.6.6"

    - name: Install SOPS and Age
      run: |
        # Install SOPS
        wget https://github.com/getsops/sops/releases/download/v3.8.1/sops-v3.8.1.linux.amd64
        sudo mv sops-v3.8.1.linux.amd64 /usr/local/bin/sops
        sudo chmod +x /usr/local/bin/sops
        
        # Install Age
        wget https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz
        tar xzf age-v1.1.1-linux-amd64.tar.gz
        sudo mv age/age /usr/local/bin/
        sudo mv age/age-keygen /usr/local/bin/

    - name: Setup Age private key
      env:
        SOPS_AGE_KEY: ${{ secrets.SOPS_AGE_KEY }}
      run: |
        mkdir -p ~/.config/sops/age
        echo "$SOPS_AGE_KEY" > ~/.config/sops/age/keys.txt
        chmod 600 ~/.config/sops/age/keys.txt

    - name: Create Python substitution script
      run: |
        cat > /tmp/substitute.py << 'EOF'
        import re
        import sys

        def parse_env_file(env_file_path):
            """Parse environment file and return key-value pairs."""
            env_vars = {}
            with open(env_file_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    # Skip empty lines and comments
                    if not line or line.startswith('#'):
                        continue
                    
                    # Split on first = only
                    if '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        
                        # Store the value with its original quotes
                        env_vars[key] = value
            return env_vars

        def substitute_vars(compose_content, env_vars):
            """Substitute environment variables in compose content."""
            # First, find all variable patterns and determine replacements on ORIGINAL content
            var_pattern = r'\$\{([^}]+)\}'
            replacements = {}  # full_match -> replacement
            
            for match in re.finditer(var_pattern, compose_content):
                full_match = match.group(0)  # ${VAR}
                var_name = match.group(1)    # VAR
                
                if var_name in env_vars and full_match not in replacements:
                    value = env_vars[var_name]
                    
                    # Find the line containing this variable (using original positions)
                    line_start = compose_content.rfind('\n', 0, match.start()) + 1
                    line_end = compose_content.find('\n', match.end())
                    if line_end == -1:
                        line_end = len(compose_content)
                    line = compose_content[line_start:line_end]
                    
                    # Check if the value in env file was quoted
                    is_quoted = (value.startswith('"') and value.endswith('"')) or \
                              (value.startswith("'") and value.endswith("'"))
                    
                    # Check if we're in a Docker Compose environment list context: "- VAR=${...}"
                    # In this context, everything after = is already a string, no quotes needed
                    is_env_list_context = re.match(r'^\s*-\s*[A-Za-z_][A-Za-z0-9_]*=\$\{', line)
                    
                    if is_quoted:
                        replacement = value
                    elif is_env_list_context:
                        replacement = value
                    else:
                        if ' ' in value or ':' in value or '#' in value or value.startswith('{') or value.startswith('[') or value.startswith('http'):
                            replacement = f'"{value}"'
                        else:
                            replacement = value
                    
                    replacements[full_match] = replacement
            
            # Now apply all replacements
            for full_match, replacement in replacements.items():
                compose_content = compose_content.replace(full_match, replacement)
            
            return compose_content

        if __name__ == "__main__":
            env_file = sys.argv[1]
            compose_file = sys.argv[2]
            
            # Parse environment variables
            env_vars = parse_env_file(env_file)
            
            # Read compose file
            with open(compose_file, 'r') as f:
                compose_content = f.read()
            
            # Substitute variables
            updated_content = substitute_vars(compose_content, env_vars)
            
            # Write back to compose file
            with open(compose_file, 'w') as f:
                f.write(updated_content)
            
            print("Environment variable substitution completed successfully")
        EOF

    - name: Process compose files with environment variables
      run: |
        # Create temporary directory
        mkdir -p /tmp/compose
        
        # Find all compose files
        for service_dir in portainer/stacks/*/; do
          service_name=$(basename "$service_dir")
          compose_file="${service_dir}docker-compose.yml"
          env_file="${service_dir}${service_name}.env"
          secrets_env_file="${service_dir}${service_name}.secrets.env"
          
          if [ -f "$compose_file" ]; then
            # Copy original compose file
            cp "$compose_file" "/tmp/compose/${service_name}.yml"
            
            # If env file exists, decrypt and substitute
            if [ -f "$env_file" ]; then
              echo "Processing ${service_name}..."
              
              # Decrypt the env file
              sops -d "$env_file" > "/tmp/${service_name}.env"
              
              # Debug: Show the decrypted env file (with sensitive values masked)
              echo "=== Decrypted environment file (sensitive values masked) ==="
              sed 's/=.*/=***/' "/tmp/${service_name}.env"
              echo "=========================="
              
              # Run the Python script
              python3 /tmp/substitute.py "/tmp/${service_name}.env" "/tmp/compose/${service_name}.yml"
              
              # Debug: Show the processed file
              echo "=== Processed compose file ==="
              cat "/tmp/compose/${service_name}.yml"
              echo -e "\n=========================="
              
              # Debug: Show any remaining ${VAR} patterns
              echo "=== Checking for unsubstituted variables ==="
              grep -o '\${[^}]*}' "/tmp/compose/${service_name}.yml" | sort -u
              echo "=========================="
              
              # Debug: Validate YAML
              echo "=== Validating YAML ==="
              python3 -c "import yaml, sys; yaml.safe_load(open('/tmp/compose/${service_name}.yml', 'r')) or sys.exit(1)"
              echo "=========================="
              
              # Update the terraform file to point to the processed compose file
              if [ -f "portainer/terraform/${service_name}.tf" ]; then
                # Update stack_file_path
                sed -i "s|stack_file_path.*=.*|stack_file_path   = \"/tmp/compose/${service_name}.yml\"|" "portainer/terraform/${service_name}.tf"
              fi
            fi
          fi
        done

    - name: Configure R2 Credentials
      run: |
        mkdir -p ~/.aws
        cat > ~/.aws/credentials << EOL
        [default]
        aws_access_key_id = ${{ secrets.R2_TF_PORTAINER_ACCESS_KEY_ID }}
        aws_secret_access_key = ${{ secrets.R2_TF_PORTAINER_SECRET_ACCESS_KEY }}
        EOL
        
        cat > ~/.aws/config << EOL
        [default]
        region = auto
        s3 =
          endpoint_url = https://${{ secrets.CF_ACCOUNT_ID }}.r2.cloudflarestorage.com
          use_path_style_endpoint = true
        EOL

    - name: Update backend configuration
      run: |
        sed -i "s/\${CF_ACCOUNT_ID}/${{ secrets.CF_ACCOUNT_ID }}/" portainer/terraform/backend.tf

    - name: Terraform Init
      run: terraform init -upgrade
      working-directory: ./portainer/terraform

    - name: Terraform Plan
      run: |
        # Ensure we're using the processed compose files
        for service in $(find portainer/terraform -maxdepth 1 -name "*.tf" -not -name "main.tf" -not -name "backend.tf" -not -name "vars.tf" -not -name "provider.tf" -not -name "network.tf" | xargs -n1 basename | sed 's/\.tf$//'); do
          if [ -f "/tmp/compose/${service}.yml" ]; then
            sed -i "s|stack_file_path.*=.*|stack_file_path   = \"/tmp/compose/${service}.yml\"|" "portainer/terraform/${service}.tf"
          fi
        done
        terraform plan -out=tfplan-infra
      working-directory: ./portainer/terraform
      env:
        TF_VAR_portainer_api_key: ${{ secrets.PORTAINER_API_KEY }}

    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: |
        # Ensure we're using the processed compose files
        for service in $(find portainer/terraform -maxdepth 1 -name "*.tf" -not -name "main.tf" -not -name "backend.tf" -not -name "vars.tf" -not -name "provider.tf" -not -name "network.tf" | xargs -n1 basename | sed 's/\.tf$//'); do
          if [ -f "/tmp/compose/${service}.yml" ]; then
            sed -i "s|stack_file_path.*=.*|stack_file_path   = \"/tmp/compose/${service}.yml\"|" "portainer/terraform/${service}.tf"
          fi
        done
        MAX_RETRIES=3
        RETRY_DELAY=30
        for attempt in $(seq 1 $MAX_RETRIES); do
          echo "Attempt $attempt of $MAX_RETRIES..."
          if terraform apply -auto-approve tfplan-infra 2>&1; then
            echo "Apply succeeded on attempt $attempt"
            exit 0
          fi
          if [ $attempt -lt $MAX_RETRIES ]; then
            echo "Apply failed, waiting ${RETRY_DELAY}s before retry..."
            sleep $RETRY_DELAY
            terraform plan -out=tfplan-infra
          fi
        done
        echo "All $MAX_RETRIES attempts failed"
        exit 1
      working-directory: ./portainer/terraform
      env:
        TF_VAR_portainer_api_key: ${{ secrets.PORTAINER_API_KEY }}

    - name: Cleanup
      if: always()
      run: |
        rm -f /tmp/*.env
        rm -f /tmp/compose/*.yml
        rm -f /tmp/substitute.py
        rm -f ~/.config/sops/age/keys.txt

  deploy-services:
    needs: [detect-changes, deploy-infrastructure]
    runs-on: ubuntu-latest
    if: >-
      always() && 
      needs.detect-changes.result == 'success' && 
      (
        (
          needs.deploy-infrastructure.result == 'success' &&
          needs.detect-changes.outputs.all-services-list != '[]'
        ) ||
        (
          needs.detect-changes.outputs.services != '[]' &&
          (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
        )
      )
    strategy:
      matrix:
        service: >-
          ${{
            needs.deploy-infrastructure.result == 'success'
            && fromJson(needs.detect-changes.outputs.all-services-list)
            || fromJson(needs.detect-changes.outputs.services)
          }}
      fail-fast: false
    steps:
    - name: Debug job conditions
      run: |
        echo "Services from detect-changes: ${{ needs.detect-changes.outputs.services }}"
        echo "Event name: ${{ github.event_name }}"
        echo "Workflow run conclusion: ${{ github.event.workflow_run.conclusion }}"
        echo "First condition: ${{ needs.detect-changes.outputs.services != '[]' || github.event_name == 'workflow_dispatch' }}"
        echo "Second condition: ${{ github.event_name == 'workflow_dispatch' || github.event_name == 'push' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success') }}"
        echo "Combined condition: ${{ (needs.detect-changes.outputs.services != '[]' || github.event_name == 'workflow_dispatch') && (github.event_name == 'workflow_dispatch' || github.event_name == 'push' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')) }}"

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: "1.6.6"

    - name: Install SOPS and Age
      run: |
        # Install SOPS
        wget https://github.com/getsops/sops/releases/download/v3.8.1/sops-v3.8.1.linux.amd64
        sudo mv sops-v3.8.1.linux.amd64 /usr/local/bin/sops
        sudo chmod +x /usr/local/bin/sops
        
        # Install Age
        wget https://github.com/FiloSottile/age/releases/download/v1.1.1/age-v1.1.1-linux-amd64.tar.gz
        tar xzf age-v1.1.1-linux-amd64.tar.gz
        sudo mv age/age /usr/local/bin/
        sudo mv age/age-keygen /usr/local/bin/

    - name: Setup Age private key
      env:
        SOPS_AGE_KEY: ${{ secrets.SOPS_AGE_KEY }}
      run: |
        mkdir -p ~/.config/sops/age
        echo "$SOPS_AGE_KEY" > ~/.config/sops/age/keys.txt
        chmod 600 ~/.config/sops/age/keys.txt

    - name: Check service files exist
      id: check-files
      run: |
        SERVICE="${{ matrix.service }}"
        
        # Check if terraform file exists
        if [ -f "portainer/terraform/${SERVICE}.tf" ]; then
          echo "terraform-exists=true" >> $GITHUB_OUTPUT
        else
          echo "terraform-exists=false" >> $GITHUB_OUTPUT
        fi
        
        # Check if env file exists
        if [ -f "portainer/stacks/${SERVICE}/${SERVICE}.env" ]; then
          echo "env-exists=true" >> $GITHUB_OUTPUT
        else
          echo "env-exists=false" >> $GITHUB_OUTPUT
        fi
        
        # Check if compose file exists
        if [ -f "portainer/stacks/${SERVICE}/docker-compose.yml" ]; then
          echo "compose-exists=true" >> $GITHUB_OUTPUT
        else
          echo "compose-exists=false" >> $GITHUB_OUTPUT
        fi

    - name: Create Python substitution script
      run: |
        cat > /tmp/substitute.py << 'EOF'
        import re
        import sys

        def parse_env_file(env_file_path):
            """Parse environment file and return key-value pairs."""
            env_vars = {}
            with open(env_file_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    # Skip empty lines and comments
                    if not line or line.startswith('#'):
                        continue
                    
                    # Split on first = only
                    if '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        
                        # Store the value with its original quotes
                        env_vars[key] = value
            return env_vars

        def substitute_vars(compose_content, env_vars):
            """Substitute environment variables in compose content."""
            # First, find all variable patterns and determine replacements on ORIGINAL content
            var_pattern = r'\$\{([^}]+)\}'
            replacements = {}  # full_match -> replacement
            
            for match in re.finditer(var_pattern, compose_content):
                full_match = match.group(0)  # ${VAR}
                var_name = match.group(1)    # VAR
                
                if var_name in env_vars and full_match not in replacements:
                    value = env_vars[var_name]
                    
                    # Find the line containing this variable (using original positions)
                    line_start = compose_content.rfind('\n', 0, match.start()) + 1
                    line_end = compose_content.find('\n', match.end())
                    if line_end == -1:
                        line_end = len(compose_content)
                    line = compose_content[line_start:line_end]
                    
                    # Check if the value in env file was quoted
                    is_quoted = (value.startswith('"') and value.endswith('"')) or \
                              (value.startswith("'") and value.endswith("'"))
                    
                    # Check if we're in a Docker Compose environment list context: "- VAR=${...}"
                    # In this context, everything after = is already a string, no quotes needed
                    is_env_list_context = re.match(r'^\s*-\s*[A-Za-z_][A-Za-z0-9_]*=\$\{', line)
                    
                    if is_quoted:
                        replacement = value
                    elif is_env_list_context:
                        replacement = value
                    else:
                        if ' ' in value or ':' in value or '#' in value or value.startswith('{') or value.startswith('[') or value.startswith('http'):
                            replacement = f'"{value}"'
                        else:
                            replacement = value
                    
                    replacements[full_match] = replacement
            
            # Now apply all replacements
            for full_match, replacement in replacements.items():
                compose_content = compose_content.replace(full_match, replacement)
            
            return compose_content

        if __name__ == "__main__":
            env_file = sys.argv[1]
            compose_file = sys.argv[2]
            
            # Parse environment variables
            env_vars = parse_env_file(env_file)
            
            # Read compose file
            with open(compose_file, 'r') as f:
                compose_content = f.read()
            
            # Substitute variables
            updated_content = substitute_vars(compose_content, env_vars)
            
            # Write back to compose file
            with open(compose_file, 'w') as f:
                f.write(updated_content)
            
            print("Environment variable substitution completed successfully")
        EOF

    - name: Process compose file with environment variables
      if: steps.check-files.outputs.compose-exists == 'true'
      run: |
        SERVICE="${{ matrix.service }}"
        
        # Create temporary directory
        mkdir -p /tmp/compose
        
        # Copy original compose file
        cp "portainer/stacks/${SERVICE}/docker-compose.yml" "/tmp/compose/${SERVICE}.yml"
        
        # If env file exists, decrypt and substitute
        if [ -f "portainer/stacks/${SERVICE}/${SERVICE}.env" ]; then
          echo "Decrypting and processing environment file..."
          
          # Decrypt the service-specific env file
          sops -d "portainer/stacks/${SERVICE}/${SERVICE}.env" > "/tmp/${SERVICE}.env"
          
          # Debug: Show the decrypted env file (with sensitive values masked)
          echo "=== Decrypted environment file (sensitive values masked) ==="
          sed 's/=.*/=***/' "/tmp/${SERVICE}.env"
          echo "=========================="
          
          # Run the Python script
          python3 /tmp/substitute.py "/tmp/${SERVICE}.env" "/tmp/compose/${SERVICE}.yml"
          
          # Debug: Show the processed file
          echo "=== Processed compose file ==="
          cat "/tmp/compose/${SERVICE}.yml"
          echo -e "\n=========================="
          
          # Debug: Show any remaining ${VAR} patterns
          echo "=== Checking for unsubstituted variables ==="
          grep -o '\${[^}]*}' "/tmp/compose/${SERVICE}.yml" | sort -u
          echo "=========================="
        fi
        
        # Update the terraform file to point to the processed compose file
        if [ -f "portainer/terraform/${SERVICE}.tf" ]; then
          sed -i "s|stack_file_path.*=.*|stack_file_path   = \"/tmp/compose/${SERVICE}.yml\"|" "portainer/terraform/${SERVICE}.tf"
        fi

    - name: Configure R2 Credentials
      run: |
        mkdir -p ~/.aws
        cat > ~/.aws/credentials << EOL
        [default]
        aws_access_key_id = ${{ secrets.R2_TF_PORTAINER_ACCESS_KEY_ID }}
        aws_secret_access_key = ${{ secrets.R2_TF_PORTAINER_SECRET_ACCESS_KEY }}
        EOL
        
        cat > ~/.aws/config << EOL
        [default]
        region = auto
        s3 =
          endpoint_url = https://${{ secrets.CF_ACCOUNT_ID }}.r2.cloudflarestorage.com
          use_path_style_endpoint = true
        EOL

    - name: Update backend configuration
      run: |
        sed -i "s/\${CF_ACCOUNT_ID}/${{ secrets.CF_ACCOUNT_ID }}/" portainer/terraform/backend.tf

    - name: Terraform Init
      if: steps.check-files.outputs.terraform-exists == 'true'
      run: terraform init -upgrade
      working-directory: ./portainer/terraform

    - name: Terraform Plan
      if: steps.check-files.outputs.terraform-exists == 'true'
      run: |
        SERVICE="${{ matrix.service }}"
        # Remove any existing plan file
        rm -f "tfplan-${SERVICE}"
        # Create new plan
        terraform plan -target="portainer_stack.${SERVICE}_stack" -out="tfplan-${SERVICE}"
      working-directory: ./portainer/terraform
      env:
        TF_VAR_portainer_api_key: ${{ secrets.PORTAINER_API_KEY }}

    - name: Terraform Apply
      if: steps.check-files.outputs.terraform-exists == 'true' && github.ref == 'refs/heads/main'
      run: |
        SERVICE="${{ matrix.service }}"
        MAX_RETRIES=3
        RETRY_DELAY=30
        for attempt in $(seq 1 $MAX_RETRIES); do
          echo "Attempt $attempt of $MAX_RETRIES..."
          if terraform apply -auto-approve "tfplan-${SERVICE}" 2>&1; then
            echo "Apply succeeded on attempt $attempt"
            rm -f "tfplan-${SERVICE}"
            exit 0
          fi
          if [ $attempt -lt $MAX_RETRIES ]; then
            echo "Apply failed, waiting ${RETRY_DELAY}s before retry..."
            sleep $RETRY_DELAY
            # Re-plan since the plan file is consumed on failure
            terraform plan -target="portainer_stack.${SERVICE}_stack" -out="tfplan-${SERVICE}"
          fi
        done
        echo "All $MAX_RETRIES attempts failed"
        rm -f "tfplan-${SERVICE}"
        exit 1
      working-directory: ./portainer/terraform
      env:
        TF_VAR_portainer_api_key: ${{ secrets.PORTAINER_API_KEY }}

    - name: Cleanup
      if: always()
      run: |
        SERVICE="${{ matrix.service }}"
        rm -f "/tmp/${SERVICE}.env"
        rm -f "/tmp/compose/${SERVICE}.yml"
        rm -f "/tmp/substitute.py"
        rm -f ~/.config/sops/age/keys.txt

  destroy-services:
    needs: [detect-changes]
    runs-on: ubuntu-latest
    if: >-
      needs.detect-changes.outputs.deleted-services != '[]' &&
      needs.detect-changes.outputs.deleted-services != '' &&
      (github.event_name == 'push' || github.event_name == 'workflow_dispatch')
    strategy:
      matrix:
        service: ${{ fromJson(needs.detect-changes.outputs.deleted-services) }}
      fail-fast: false
    steps:
    - name: Debug destroy job
      run: |
        echo "Destroying service: ${{ matrix.service }}"
        echo "Event name: ${{ github.event_name }}"

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: "1.6.6"

    - name: Configure R2 Credentials
      run: |
        mkdir -p ~/.aws
        cat > ~/.aws/credentials << EOL
        [default]
        aws_access_key_id = ${{ secrets.R2_TF_PORTAINER_ACCESS_KEY_ID }}
        aws_secret_access_key = ${{ secrets.R2_TF_PORTAINER_SECRET_ACCESS_KEY }}
        EOL
        
        cat > ~/.aws/config << EOL
        [default]
        region = auto
        s3 =
          endpoint_url = https://${{ secrets.CF_ACCOUNT_ID }}.r2.cloudflarestorage.com
          use_path_style_endpoint = true
        EOL

    - name: Update backend configuration
      run: |
        sed -i "s/\${CF_ACCOUNT_ID}/${{ secrets.CF_ACCOUNT_ID }}/" portainer/terraform/backend.tf

    - name: Terraform Init
      run: terraform init -upgrade
      working-directory: ./portainer/terraform

    - name: Terraform Destroy
      if: github.ref == 'refs/heads/main'
      run: |
        SERVICE="${{ matrix.service }}"
        echo "Destroying stack: ${SERVICE}"
        # Destroy the specific resource that was removed
        terraform destroy -target="portainer_stack.${SERVICE}_stack" -auto-approve
      working-directory: ./portainer/terraform
      env:
        TF_VAR_portainer_api_key: ${{ secrets.PORTAINER_API_KEY }}